---
title: "Assignment 1"
author: "Joan Shim and Beimnet Taye"
date: "2024-02-04"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, message = F, warning = F)
library(tidyverse)
library(knitr)
```

```{r samp}
library(survival)
expit <- function(x) exp(x)/(1+exp(x))



sim_conf <- function(i, N=1000, a_u=rep(0,2), a_x = rep(0,3), b = rep(0,4)){
# Data generating mechanism:
W <- runif(N)
# Simulate unmeasured confounder
pi_u <- expit(a_u[1] + W*a_u[2])
U <- rbinom(N,1,pi_u)
# Simulate exposure
pi_x <- expit(a_x[1] + W*a_x[2] + U*a_x[3])
X <- rbinom(N,1,pi_x)
# Simulate exponentially distributed survival times (no censoring)
lambda_y <- exp(b[1] + X*b[2] + W*b[3] + U*b[4])
Y <- rexp(N,lambda_y)
# Fit models:
fit_adj <- coxph(Surv(Y) ~ X + W + U) # Fully adjusted Cox model
fit_un <- coxph(Surv(Y) ~ X + W) # Partially adjusted Cox model
# Collect exposure coefficients
b_adj <- coef(fit_adj)["X"]
b_un <- coef(fit_un)["X"]
# Return
return(c(b_adj, b_un))
}
```

```{r set}
N <- 10000 # Sample size
N.sim <- 1000 # Number of simulations
# Parameters for data generating mechanisms for U and X
# (constant across all scenarios)
a_u <- c(.5, -2)
a_x <- c(.5, .1, -.3)
```

```{r simple}
# Scenario 1
set.seed(123) # Set random number seed for reproducibility
# Parameter for DGM for Y #### COMPLETE ON YOUR OWN
b <- c(log(0.01), log(1.5),0,0)
# Run simulation and transpose the results (better orientation for reporting)
beta_hat_un <- sapply(1:N.sim, sim_conf, N=N, a_u = a_u, a_x = a_x, b=b) |> t()
```

```{r obsv}
# Scenario 2
set.seed(123) # Set random number seed for reproducibility
# Parameter for DGM for Y #### COMPLETE ON YOUR OWN
b_c1 <- c(log(0.01), log(1.5),-.7,0)
# Run simulation and transpose the results (better orientation for reporting)
beta_hat_c1 <- sapply(1:N.sim, sim_conf, N=N, a_u = a_u, a_x = a_x, b=b_c1) |> t()
```

```{r unmeas}
# Confounding scenario 2
set.seed(123) # Set random number seed for reproducibility
# Parameter for DGM for Y #### COMPLETE ON YOUR OWN
b_c2 <- c(log(0.01), log(1.5),-.7,.5)
# Run simulation and transpose the results (better orientation for reporting)
beta_hat_c2 <- sapply(1:N.sim, sim_conf, N=N, a_u = a_u, a_x = a_x, b=b_c2) |> t()
```

```{r proc}
# Convert estimated coefficients to HRs:
HR_hat_un <- exp(beta_hat_un)
HR_hat_c1 <- exp(beta_hat_c1)
HR_hat_c2 <- exp(beta_hat_c2)
colnames(HR_hat_un) <- colnames(HR_hat_c1) <- colnames(HR_hat_c2) <-
c("Fully adjusted","Partially adjusted")
HR_un <- apply(HR_hat_un, 2, median) |> round(2)
HR_c1 <- apply(HR_hat_c1, 2, median) |> round(2)
HR_c2 <- apply(HR_hat_c2, 2, median) |> round(2)
```

```{r plot}
# pdf("Simulation_Plot_Confounding.pdf") # Uncomment to save to PDF file
# par(mfrow=c(3,1))
# plot(density(HR_hat_un[,1]), main="Unconfounded", xlab="HR")
# lines(density(HR_hat_un[,2]), lty=2)
# legend("topleft",
# legend=c("Fully adjusted","Partially adjusted"),
# lty=c(1,2))
# plot(density(HR_hat_c1[,1]), main="Confounding scenario 1", xlab="HR")
# lines(density(HR_hat_c1[,2]), lty=2)
# legend("topleft",
# legend=c("Fully adjusted","Partially adjusted"),
# lty=c(1,2))
# plot(density(HR_hat_c2[,1]), main="Confounding scenario 2", xlab="HR")
# lines(density(HR_hat_c2[,2]), lty=2)
# legend("topleft",
# legend=c("Fully adjusted","Partially adjusted"),
# lty=c(1,2))
# par(mfrow=c(1,1))
# dev.off() # Uncomment if saving plot to PDF file
```
# Q1.
```{r}
tibble(
  stuff = c("a_u,1","a_u,2","a_x,1","a_x,2","a_x,3","B1","B2","B3","B4"),
  Unconfounded = c(a_u[1],a_u[2],a_x[1],a_x[2],a_x[3],b[1],b[2],b[3],b[4]),
  C_1 = c(a_u[1],a_u[2],a_x[1],a_x[2],a_x[3],b_c1[1],b_c1[2],b_c1[3],b_c1[4]),
  C_2 = c(a_u[1],a_u[2],a_x[1],a_x[2],a_x[3],b_c2[1],b_c2[2],b_c2[3],b_c2[4])) %>% 
  kable(booktabs = T, col.names = c(" ", "Unconfounded", "Confounding 1", "Confounding 2"), digits = 2) %>% 
  kableExtra::kable_styling(latex_options = c("striped", "HOLD_position"))
```

\newpage

# Q2

Confounding Scenario 2 since the DGP of the outcome in this scenario involves a non-zero (non-null) value for B4.

\newpage

# Q3

```{r q3}
HR_tab<- rbind(HR_un, HR_c1,HR_c2)


rownames(HR_tab)<- c("Unconfounded", "Confounding 1", "Confounding 2")

HR_tab %>% 
  kable(booktabs = T) %>% 
  kableExtra::kable_styling(latex_options = c("striped", "HOLD_position"))
```

\newpage

# Q4

```{r q4}
library(here)
include_graphics(here("assignments","assign 1", "Simulation_Plot_Confounding.png"))
```

\newpage

# Q5

The partially adjusted model is only biased under confounding scenario 2. The underlying code is correct since we expect the simulated X HRs to be about 1.5, the true X HR, for both the partially and fully adjusted models under the unconfounded and the first confounding scenario, which both the plots and the data show. This is because the unconfounded and first scenarios are parameterized with null relationships between Y and U, thus omitting U in the model won't affect Y. In scenario 2 the introduction of a non null relationship between Y and U in the DGP resulted in a biased estimate for the HR of X in the partially adjusted model with the HR biased towards the null. If we wanted to simulate different strengths of the confounding we could vary the U beta coefficient resulting in different parameterizations of the underlying exponential distribution for Y, thus altering the affect of U on Y. Additionally, we can change the $\alpha_{x,3}$ parameter altering U's affect on X changing the nature of the underlying binomial distribution of X and thus altering the affect of U as a confounder.  